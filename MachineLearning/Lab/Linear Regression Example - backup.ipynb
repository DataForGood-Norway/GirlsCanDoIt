{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Linear Regression using GapMinder Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a very simple example of machine learning we're going see if we can predict life expectancy using some data from [GapMinder](https://www.gapminder.org/tools/#_data_/_lastModified:1526038652718&lastModified:1526038652718;&chart-type=bubbles), an organisation that aims to educate us more on the true state of the world.\n",
    "The input data set will have 136 countries with the following variables:\n",
    "- Continent\n",
    "- Life expectancy\n",
    "- GDP per capita, PPP, inflation adjusted\n",
    "- Healthcare spend as a percentage of GDP\n",
    "- Population per square km \n",
    "- The democracy index of the country (high is better). See https://en.wikipedia.org/wiki/Democracy_Index\n",
    "\n",
    "Go to [GapMinder](https://www.gapminder.org/tools/#_data_/_lastModified:1526038652718&lastModified:1526038652718;&chart-type=bubbles) now and take a look at some of these variable in the data viewer.  \n",
    "- Do any of the variables (visually) look like they have a bearing on life expectancy?  \n",
    "- Are any of them surprising?\n",
    "\n",
    "#### Question: is there a country that is particularly inefficient in terms of healthcare spend?\n",
    "<img src=\"files/Screen Shot from gapminder.png\" alt=\"GDP per Capita vs. Life Expectancy from Gapminder\" title=\"GDP per Capita vs. Life Expectancy from Gapminder\" style=\"width: 50pc;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we know which variables to use?\n",
    "When we have a number of variables, it may not be immediately apparent which ones influence the final result.  We will usually find that we can and should  drop one or more independent variables because:\n",
    "- We don't want to include variables that aren't significant\n",
    "<img src=\"files/GarbageInGarbageOut.png\" alt=\"Garbage In - Garbage out\" title=\"Garbage In - Garbage Out\" style=\"width: 25pc;\"/>\n",
    "- When you are presenting your results you will have to explain why you included a variable; \"because I had the data\" is not a good enough reason!\n",
    "\n",
    "There are several ways to acheive but we will concentrate on \"backward elimination\".  To understand this you need to know about the \"P\" value.  A proper explanation is [here](https://www.mathbootcamps.com/what-is-a-p-value) but for now we'll just say that the lower the P value is, the more significant the variable.\n",
    "\n",
    "## Backward elimination\n",
    "1. Choose a maximum P value: 5% is a good value\n",
    "2. Run the linear regression using all the dependent variables. \n",
    "3. Look at the P values from the output, and choose the biggest.  \n",
    "4. If it is > than 5%, then drop that variable.\n",
    "5. Rerun the linear regression.\n",
    "6. Repeat steps 2-5 until all P-values are < 5%.  \n",
    "\n",
    "#### I will take you up to step 5, then the rest will be up to you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding\n",
    "Firstly we need to import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-04 04:53:25--  https://raw.githubusercontent.com/DataForGood-Norway/GirlsCanDoIt/master/MachineLearning/Lab/python/plot_functions.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.84.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.84.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1299 (1.3K) [text/plain]\n",
      "Saving to: ‘plot_functions.py’\n",
      "\n",
      "plot_functions.py   100%[===================>]   1.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2018-06-04 04:53:26 (44.2 MB/s) - ‘plot_functions.py’ saved [1299/1299]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standard library for numerical analysis\n",
    "import numpy as np\n",
    "# Standard library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# User-defined library for making plots\n",
    "import sys\n",
    "!mkdir -p local_modules/\n",
    "!cd local_modules\n",
    "!wget https://raw.githubusercontent.com/DataForGood-Norway/GirlsCanDoIt/master/MachineLearning/Lab/python/plot_functions.py\n",
    "!cd ..\n",
    "sys.path.append('local_modules')\n",
    "from plot_functions import make_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset\n",
    "\n",
    "Next we will import the dataset with data for 2007, which has the following columns:\n",
    "- Country - 136 countries are included\n",
    "- Continent\n",
    "- lifeexp - Life expectancy\n",
    "- gdpPercap - GDP per capita, PPP, inflation adjusted\n",
    "- health_spend - Healthcare spend as a percentage of GDP\n",
    "- Pop density - popultaion per square km\n",
    "- Democracy - The democracy index of the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>pop</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>health_spend</th>\n",
       "      <th>Pop density</th>\n",
       "      <th>Democracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>43.828</td>\n",
       "      <td>31889923</td>\n",
       "      <td>974.580338</td>\n",
       "      <td>7.3</td>\n",
       "      <td>44.696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.423</td>\n",
       "      <td>3600523</td>\n",
       "      <td>5937.029526</td>\n",
       "      <td>6.9</td>\n",
       "      <td>110.257</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Africa</td>\n",
       "      <td>72.301</td>\n",
       "      <td>33333216</td>\n",
       "      <td>6223.367465</td>\n",
       "      <td>3.5</td>\n",
       "      <td>14.236</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.731</td>\n",
       "      <td>12420476</td>\n",
       "      <td>4797.231267</td>\n",
       "      <td>2.5</td>\n",
       "      <td>14.057</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Americas</td>\n",
       "      <td>75.320</td>\n",
       "      <td>40301927</td>\n",
       "      <td>12779.379640</td>\n",
       "      <td>8.4</td>\n",
       "      <td>14.159</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>81.235</td>\n",
       "      <td>20434176</td>\n",
       "      <td>34435.367440</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.728</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Europe</td>\n",
       "      <td>79.829</td>\n",
       "      <td>8199783</td>\n",
       "      <td>36126.492700</td>\n",
       "      <td>10.2</td>\n",
       "      <td>99.094</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Asia</td>\n",
       "      <td>75.635</td>\n",
       "      <td>708573</td>\n",
       "      <td>29796.048340</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1333.909</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>Asia</td>\n",
       "      <td>64.062</td>\n",
       "      <td>150448339</td>\n",
       "      <td>1391.253792</td>\n",
       "      <td>3.5</td>\n",
       "      <td>999.714</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>Europe</td>\n",
       "      <td>79.441</td>\n",
       "      <td>10392226</td>\n",
       "      <td>33692.605080</td>\n",
       "      <td>9.6</td>\n",
       "      <td>345.216</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Benin</td>\n",
       "      <td>Africa</td>\n",
       "      <td>56.728</td>\n",
       "      <td>8078314</td>\n",
       "      <td>1441.284873</td>\n",
       "      <td>4.6</td>\n",
       "      <td>72.034</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bolivia</td>\n",
       "      <td>Americas</td>\n",
       "      <td>65.554</td>\n",
       "      <td>9119152</td>\n",
       "      <td>3822.137084</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.614</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>Europe</td>\n",
       "      <td>74.852</td>\n",
       "      <td>4552198</td>\n",
       "      <td>7446.298803</td>\n",
       "      <td>9.8</td>\n",
       "      <td>73.814</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country continent  lifeExp        pop     gdpPercap  \\\n",
       "0              Afghanistan      Asia   43.828   31889923    974.580338   \n",
       "1                  Albania    Europe   76.423    3600523   5937.029526   \n",
       "2                  Algeria    Africa   72.301   33333216   6223.367465   \n",
       "3                   Angola    Africa   42.731   12420476   4797.231267   \n",
       "4                Argentina  Americas   75.320   40301927  12779.379640   \n",
       "5                Australia   Oceania   81.235   20434176  34435.367440   \n",
       "6                  Austria    Europe   79.829    8199783  36126.492700   \n",
       "7                  Bahrain      Asia   75.635     708573  29796.048340   \n",
       "8               Bangladesh      Asia   64.062  150448339   1391.253792   \n",
       "9                  Belgium    Europe   79.441   10392226  33692.605080   \n",
       "10                   Benin    Africa   56.728    8078314   1441.284873   \n",
       "11                 Bolivia  Americas   65.554    9119152   3822.137084   \n",
       "12  Bosnia and Herzegovina    Europe   74.852    4552198   7446.298803   \n",
       "\n",
       "    health_spend  Pop density  Democracy  \n",
       "0            7.3       44.696        NaN  \n",
       "1            6.9      110.257        9.0  \n",
       "2            3.5       14.236        2.0  \n",
       "3            2.5       14.057       -2.0  \n",
       "4            8.4       14.159        8.0  \n",
       "5            8.5        2.728       10.0  \n",
       "6           10.2       99.094       10.0  \n",
       "7            3.6     1333.909       -7.0  \n",
       "8            3.5      999.714       -6.0  \n",
       "9            9.6      345.216        8.0  \n",
       "10           4.6       72.034        7.0  \n",
       "11           4.7        8.614        8.0  \n",
       "12           9.8       73.814        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('https://raw.githubusercontent.com/DataForGood-Norway/GirlsCanDoIt/master/MachineLearning/Lab/datasets/gapminder_2007_emma.csv')\n",
    "dataset.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "To get ready for the regression we need to make sure that all the columns contain numbers only:\n",
    "- Cells that are empty currently contain \"Not a Number\" (nan) - these will be replaced with an average\n",
    "- Cells that contain words (\"categorical variables\") will be replaced with numerical values.\n",
    "\n",
    "But firstly the data now needs to be split into independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country, continent, population, GDP per cap, healthcare spend, pop density, democracy\n",
    "X = dataset.iloc[:,[0,1,3,4,5,6,7]].values\n",
    "# Will use the log of the GDP per capita because from our first look, there seems to be a log-linear realtionship\n",
    "X[:,3] = np.log(dataset.iloc[:,4].values)\n",
    "# The dependent variable is life expectancy, in column 2\n",
    "y = dataset.iloc[:, 2].values\n",
    "# Also making a list of continents for plotting purposes\n",
    "cont = dataset.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "- The cells where data is missing have \"Not a Number\" in them. The following code replaces these with the average for that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the \"NaNs\" - replace with the average of that column\n",
    "# sklearn contains libraries for preprocessing data\n",
    "# now importing Imputer class\n",
    "from sklearn.preprocessing import Imputer\n",
    "# Create object\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# Fit imputer object to feature X\n",
    "imputer = imputer.fit(X[:,2:])\n",
    "# Replace missing data with replaced values\n",
    "X[:,2:] = imputer.transform(X[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "Categorical variables are ones which have a name, not a number.  In this case that would \"Country name\" and \"Continent\".\n",
    "\n",
    "### Country name\n",
    "We only have each country listed once, and it makes no sense to use the name of the country in the regression, so we are somply going to number them 0-136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now importing LabelEncoder class\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Encoding the Independent Variable\n",
    "# Firstly assign the categorical variables a unique number using LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "# Country names are in column zero\n",
    "# Each country will get a number 0-136 (for the full dataset) \n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continent\n",
    "There are 5 continents in this dataset: Africa, Americas, Asia, Europe and Oceania.  If we simply give them a number 0-4, Python will assume that Oceania \"is greater\" than all this other continents, which makes no sense.  To fix this we use \"one-hot encoding\" which works like this:\n",
    "- Number the continents 0-4\n",
    "- Create a column for each continent -- these new columns are called __dummy variables__\n",
    "- If the country is in that continent the column contains \"1\" otherwise it contains \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now importing OneHotEncoder class\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Each continent will get a number 0-4\n",
    "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n",
    "cont = labelencoder_X.fit_transform(cont)\n",
    "\n",
    "# one hot encode continents\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variable trap\n",
    "A requirement of regression is that no column can be predicted from the others. Since any of the five columns could be predicted from the other four (known as the __dummy variable trap__) we need to drop one.\n",
    "    - Normally it would be the first column, but since Africa looks quite interesting in this dataset, I decided to drop Oceania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,[0,1,2,3,5,6,7,8,9,10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a constant\n",
    "We need to add a column of ones at the beginning, as the regression requires a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(arr = np.ones((len(X),1)).astype(int), values = X, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into tesing and training set\n",
    "This is very important!  We will first try to create the model from the training set and then apply it to the test set to see if the model has worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>africa</th>\n",
       "      <th>americas</th>\n",
       "      <th>asia</th>\n",
       "      <th>europe</th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>health_spend</th>\n",
       "      <th>logGDP</th>\n",
       "      <th>pop_density</th>\n",
       "      <th>democracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>4553009.0</td>\n",
       "      <td>10.760945</td>\n",
       "      <td>3.185626</td>\n",
       "      <td>6712.876</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8078314.0</td>\n",
       "      <td>7.273290</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>72.034</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33333216.0</td>\n",
       "      <td>8.736066</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>14.236</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>7483763.0</td>\n",
       "      <td>8.174233</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>63.868</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>798094.0</td>\n",
       "      <td>8.945088</td>\n",
       "      <td>6.551296</td>\n",
       "      <td>325.021</td>\n",
       "      <td>4.210938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  africa  americas  asia  europe  country  population  health_spend  \\\n",
       "0    1.0     0.0       0.0   1.0     0.0    108.0   4553009.0     10.760945   \n",
       "1    1.0     1.0       0.0   0.0     0.0     10.0   8078314.0      7.273290   \n",
       "2    1.0     1.0       0.0   0.0     0.0      2.0  33333216.0      8.736066   \n",
       "3    1.0     0.0       1.0   0.0     0.0     51.0   7483763.0      8.174233   \n",
       "4    1.0     1.0       0.0   0.0     0.0    100.0    798094.0      8.945088   \n",
       "\n",
       "     logGDP  pop_density  democracy  \n",
       "0  3.185626     6712.876  -2.000000  \n",
       "1  4.600000       72.034   7.000000  \n",
       "2  3.500000       14.236   2.000000  \n",
       "3  5.900000       63.868   7.000000  \n",
       "4  6.551296      325.021   4.210938  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test, cont_train, cont_test = train_test_split(X, y, cont, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\"\"\"\n",
    "Columns are now\n",
    "0: constant, 1:is Africa 2: is Americas 3: is Asia 4:is Europe\n",
    "5: country 6:population 7:log(GDP per cap) \n",
    "8:health spend 9:pop density 10: dempocracy score\n",
    "\"\"\"\n",
    "\n",
    "#Finally this is just to give column headers to the datasets \n",
    "X_train = pd.DataFrame(X_train,columns = ['const', 'africa','americas','asia','europe','country',\n",
    "                                          'population','health_spend','logGDP','pop_density','democracy'])\n",
    "X_test = pd.DataFrame(X_test,columns = ['const', 'africa','americas','asia','europe','country',\n",
    "                                          'population','health_spend','logGDP','pop_density','democracy'])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the regressor\n",
    "This is where we get to the interesting part!\n",
    "\n",
    "Firstly we will train the regressor using all the variables and see how it performs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          24.182415\n",
       "1          99.484316\n",
       "2          33.115452\n",
       "3         365.037468\n",
       "4         700.151190\n",
       "5         413.827686\n",
       "6        1808.042414\n",
       "7          29.964100\n",
       "8        4683.653890\n",
       "9         306.230964\n",
       "10      36315.502674\n",
       "11         99.484316\n",
       "12       2570.148581\n",
       "13       2697.282328\n",
       "14       4415.436254\n",
       "15        297.251672\n",
       "16        134.289780\n",
       "17       1998.195895\n",
       "18        897.847292\n",
       "19       3640.950307\n",
       "20       2980.957987\n",
       "21       2333.895806\n",
       "22       1635.984430\n",
       "23         12.182494\n",
       "24      31536.092735\n",
       "25      16317.607198\n",
       "26      26903.186074\n",
       "27       4914.768840\n",
       "28          8.166170\n",
       "29       2409.133167\n",
       "           ...      \n",
       "78        700.151190\n",
       "79       2440.601978\n",
       "80     120571.714986\n",
       "81        181.272242\n",
       "82      22026.465795\n",
       "83        331.952953\n",
       "84       1096.633158\n",
       "85        330.299560\n",
       "86         73.699794\n",
       "87          6.685894\n",
       "88        121.510418\n",
       "89        472.912882\n",
       "90      18033.744928\n",
       "91       4509.800922\n",
       "92        121.510418\n",
       "93      13359.726830\n",
       "94         81.450869\n",
       "95        134.289780\n",
       "96      18033.744928\n",
       "97        418.700723\n",
       "98        221.406416\n",
       "99         16.444647\n",
       "100      8955.292703\n",
       "101       544.571910\n",
       "102        66.686331\n",
       "103     14764.781566\n",
       "104      1726.665136\n",
       "105      4447.066748\n",
       "106      7459.346807\n",
       "107      1339.430764\n",
       "Name: logGDP, Length: 108, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Start the training\n",
    "\"\"\"\n",
    "\n",
    "#train the regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "#Make predictions\n",
    "y_pred = regressor.predict(X_train)\n",
    "\n",
    "np.exp(X_train['logGDP'])\n",
    "#plot the results\n",
    "# make_plot('GDP per cap',np.exp(X_train['logGDP']),y_train,y_pred,cont_train)\n",
    "#plot the results\n",
    "# make_plot('Health spend',X_train['health_spend'],y_train,y_pred,cont_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What can we say about the above plots?  \n",
    "#### Is there a continent that stands out from the rest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start backward elimination\n",
    "As a reminder:\n",
    "1. Choose a maximum P value: 5% is a good value\n",
    "2. Run the linear regression using all the dependent variables.\n",
    "3. Look at the P values from the output, and choose the biggest.\n",
    "4. If it is > than 5%, then drop that variable.\n",
    "5. Rerun the linear regression.\n",
    "6. Repeat steps 2-5 until all P-values are < 5%.\n",
    "\n",
    "#### The code below is the first step and then you will have a chance to get involved and complete the other steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Jun 2018</td> <th>  Prob (F-statistic):</th> <td>9.53e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:01:15</td>     <th>  Log-Likelihood:    </th> <td> -351.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   108</td>      <th>  AIC:               </th> <td>   724.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   754.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>   36.5923</td> <td>    9.214</td> <td>    3.972</td> <td> 0.000</td> <td>   18.306</td> <td>   54.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>africa</th>       <td>  -15.0632</td> <td>    5.374</td> <td>   -2.803</td> <td> 0.006</td> <td>  -25.728</td> <td>   -4.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>americas</th>     <td>   -2.0509</td> <td>    5.012</td> <td>   -0.409</td> <td> 0.683</td> <td>  -11.998</td> <td>    7.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>asia</th>         <td>   -4.9746</td> <td>    5.329</td> <td>   -0.934</td> <td> 0.353</td> <td>  -15.551</td> <td>    5.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>europe</th>       <td>   -2.0982</td> <td>    4.883</td> <td>   -0.430</td> <td> 0.668</td> <td>  -11.790</td> <td>    7.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>country</th>      <td>    0.0094</td> <td>    0.016</td> <td>    0.584</td> <td> 0.561</td> <td>   -0.023</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population</th>   <td>  1.27e-09</td> <td> 4.07e-09</td> <td>    0.312</td> <td> 0.756</td> <td>-6.81e-09</td> <td> 9.35e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health_spend</th> <td>    4.4054</td> <td>    0.715</td> <td>    6.161</td> <td> 0.000</td> <td>    2.986</td> <td>    5.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>logGDP</th>       <td>   -0.1395</td> <td>    0.300</td> <td>   -0.465</td> <td> 0.643</td> <td>   -0.735</td> <td>    0.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_density</th>  <td>    0.0004</td> <td>    0.001</td> <td>    0.409</td> <td> 0.684</td> <td>   -0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>democracy</th>    <td>   -0.0470</td> <td>    0.139</td> <td>   -0.337</td> <td> 0.736</td> <td>   -0.323</td> <td>    0.229</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.983</td> <th>  Durbin-Watson:     </th> <td>   1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.083</td> <th>  Jarque-Bera (JB):  </th> <td>   5.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.230</td> <th>  Prob(JB):          </th> <td>  0.0572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.029</td> <th>  Cond. No.          </th> <td>3.40e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.747\n",
       "Model:                            OLS   Adj. R-squared:                  0.721\n",
       "Method:                 Least Squares   F-statistic:                     28.69\n",
       "Date:                Sat, 02 Jun 2018   Prob (F-statistic):           9.53e-25\n",
       "Time:                        16:01:15   Log-Likelihood:                -351.40\n",
       "No. Observations:                 108   AIC:                             724.8\n",
       "Df Residuals:                      97   BIC:                             754.3\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const           36.5923      9.214      3.972      0.000      18.306      54.879\n",
       "africa         -15.0632      5.374     -2.803      0.006     -25.728      -4.398\n",
       "americas        -2.0509      5.012     -0.409      0.683     -11.998       7.896\n",
       "asia            -4.9746      5.329     -0.934      0.353     -15.551       5.602\n",
       "europe          -2.0982      4.883     -0.430      0.668     -11.790       7.593\n",
       "country          0.0094      0.016      0.584      0.561      -0.023       0.042\n",
       "population     1.27e-09   4.07e-09      0.312      0.756   -6.81e-09    9.35e-09\n",
       "health_spend     4.4054      0.715      6.161      0.000       2.986       5.825\n",
       "logGDP          -0.1395      0.300     -0.465      0.643      -0.735       0.455\n",
       "pop_density      0.0004      0.001      0.409      0.684      -0.002       0.003\n",
       "democracy       -0.0470      0.139     -0.337      0.736      -0.323       0.229\n",
       "==============================================================================\n",
       "Omnibus:                        4.983   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.083   Jarque-Bera (JB):                5.722\n",
       "Skew:                          -0.230   Prob(JB):                       0.0572\n",
       "Kurtosis:                       4.029   Cond. No.                     3.40e+09\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.4e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Start backward elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X_opt = X_train.loc[:,['const', 'africa','americas','asia','europe','country','population',\n",
    "                    'health_spend','logGDP','pop_density','democracy']]\n",
    "regressor_OLS = sm.OLS(endog = y_train, \n",
    "                       exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the table above.  We are particularly interested in the P-values for each variable.  What does this say about the significance of the different variables?  Are any of them surprising?\n",
    "\n",
    "#### You can plot the results using the user defined module make_plot, which sets some of the display parameters like colour and titles, without you having to type it all in every time.  The format is:\n",
    "make_plot('independent_variable',x_data,actual_data,predicted data,continents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-339400e25b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgdp_per_cap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmake_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GDP per cap'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgdp_per_cap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcont_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "regressor_new = LinearRegression()\n",
    "regressor_new.fit(X_opt,y_train)\n",
    "y_pred = regressor.predict(X_train)\n",
    "\n",
    "#plot the results\n",
    "gdp_per_cap = np.exp(X_train[:,7])\n",
    "make_plot('GDP per cap',gdp_per_cap,y_train,y_pred,cont_train)\n",
    "#plot the results\n",
    "make_plot('Health spend',X_train[:,8],y_train,y_pred,cont_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
